{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd4222ef-c4f3-41d1-ab01-07c222cf8178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from pmdarima.arima import auto_arima\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "\n",
    "# Ignore convergence warnings from statsmodels\n",
    "warnings.simplefilter(\"ignore\", ConvergenceWarning)\n",
    "\n",
    "# Set up logging configuration\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36e70344-1ca6-4a6e-a26b-c0096be0551d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_stocks_data(ticker_list, time_period):\n",
    "    \"\"\"\n",
    "    Fetch stock data from Yahoo Finance for multiple tickers and transform\n",
    "    it into a tidy DataFrame with columns: Open, High, Low, Close, Volume, Ticker.\n",
    "    The Date column will be set as the index.\n",
    "    \n",
    "    Parameters:\n",
    "    - ticker_list: List of ticker symbols (e.g., ['AAPL', 'GOOG', 'MSFT', 'TSLA'])\n",
    "    - time_period: '1m', '3m', '6m', or '1y'\n",
    "    \n",
    "    Returns:\n",
    "    - Combined DataFrame with data for all tickers, or None if an error occurs.\n",
    "    \"\"\"\n",
    "    logging.info(\"Fetching data for multiple tickers...\")\n",
    "    \n",
    "    try:\n",
    "        # Set end_date to the most recent trading day\n",
    "        end_date = datetime.now()\n",
    "        # Adjust end_date if today is weekend (market closed)\n",
    "        if end_date.weekday() == 5:      # Saturday\n",
    "            end_date -= timedelta(days=1)\n",
    "        elif end_date.weekday() == 6:    # Sunday\n",
    "            end_date -= timedelta(days=2)\n",
    "        \n",
    "        # Determine the unit and value from the custom_period string.\n",
    "        # Expected formats: \"15y\", \"6m\", \"30d\", etc.\n",
    "        unit = time_period[-1].lower()\n",
    "        try:\n",
    "            value = int(time_period[:-1])\n",
    "        except ValueError:\n",
    "            raise ValueError(\"Period must be a number followed by 'y', 'm', or 'd' (e.g., '15y', '6m', '30d').\")\n",
    "        \n",
    "        # Calculate the start_date using relativedelta for years and months.\n",
    "        if unit == 'y':\n",
    "            start_date = end_date - relativedelta(years=value)\n",
    "        elif unit == 'm':\n",
    "            start_date = end_date - relativedelta(months=value)\n",
    "        elif unit == 'd':\n",
    "            start_date = end_date - timedelta(days=value)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid period format. Use a number followed by 'y' (years), 'm' (months), or 'd' (days).\")\n",
    "        \n",
    "        # Download data for all tickers at once\n",
    "        df = yf.download(\n",
    "            ticker_list,\n",
    "            start=start_date.strftime('%Y-%m-%d'),\n",
    "            end=end_date.strftime('%Y-%m-%d'),\n",
    "            progress=False\n",
    "        )\n",
    "        \n",
    "        if df.empty:\n",
    "            logging.warning(\"No data found for provided tickers.\")\n",
    "            return None\n",
    "\n",
    "        # When multiple tickers are passed, yfinance returns a MultiIndex on columns.\n",
    "        # Stack the data into a long (tidy) format.\n",
    "        df = df.stack(level=1, future_stack=True).rename_axis(['Date', 'Ticker']).reset_index()\n",
    "        \n",
    "         # Remove any unwanted column name (e.g. \"Price\") from the columns Index.\n",
    "        df.columns.name = None\n",
    "        \n",
    "        # Set the Date column as the index for easier time series analysis.\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        df = df.set_index('Date')\n",
    "        \n",
    "        # Optionally, reorder columns if desired (e.g., Ticker as a column, then Open, High, Low, Close, Volume)\n",
    "        df = df[['Ticker', 'Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "        \n",
    "        logging.info(\"Successfully fetched and transformed data for multiple tickers.\")\n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error fetching data for multiple tickers: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "758e5701-d269-4ba4-9d2e-c48799f03ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    \"\"\"\n",
    "    Preprocess stock data (with Date as the index) and calculate technical indicators\n",
    "    separately for each ticker. Then, standardize selected exogenous variables.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame with Date as index and columns: Ticker, Open, High, Low, Close, Volume, \n",
    "          and additional engineered indicators.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with additional technical indicator columns and standardized exogenous variables,\n",
    "      or None if an error occurs.\n",
    "    \n",
    "    Note:\n",
    "    - The grouping by 'Ticker' ensures that rolling calculations and standardization are applied\n",
    "      within each stock's own time series.\n",
    "    \"\"\"\n",
    "    logging.info(\"Preprocessing data and calculating technical indicators...\")\n",
    "    \n",
    "    try:        \n",
    "        # Ensure the index is a DatetimeIndex\n",
    "        if not isinstance(df.index, pd.DatetimeIndex):\n",
    "            df.index = pd.to_datetime(df.index)\n",
    "        \n",
    "        # Forward-fill missing values\n",
    "        df = df.ffill()\n",
    "        \n",
    "        # Define a function to compute technical indicators for a single ticker's data.\n",
    "        def compute_indicators(sub_df):\n",
    "            # Sort the data by index (date) for correct rolling calculations.\n",
    "            sub_df = sub_df.sort_index()\n",
    "            \n",
    "            # Calculate moving averages (MA5, MA20) with minimum periods equal to the window size.\n",
    "            sub_df['MA5'] = sub_df['Close'].rolling(window=5, min_periods=5).mean()\n",
    "            sub_df['MA20'] = sub_df['Close'].rolling(window=20, min_periods=20).mean()\n",
    "            \n",
    "            # Calculate MACD: EMA12, EMA26, MACD, and Signal line.\n",
    "            sub_df['EMA12'] = sub_df['Close'].ewm(span=12, adjust=False).mean()\n",
    "            sub_df['EMA26'] = sub_df['Close'].ewm(span=26, adjust=False).mean()\n",
    "            sub_df['MACD'] = sub_df['EMA12'] - sub_df['EMA26']\n",
    "            sub_df['Signal'] = sub_df['MACD'].ewm(span=9, adjust=False).mean()\n",
    "            \n",
    "            # Calculate RSI over a 14-day window.\n",
    "            delta = sub_df['Close'].diff()\n",
    "            gain = delta.where(delta > 0, 0)\n",
    "            loss = -delta.where(delta < 0, 0)\n",
    "            avg_gain = gain.rolling(window=14, min_periods=14).mean()\n",
    "            avg_loss = loss.rolling(window=14, min_periods=14).mean()\n",
    "            rs = avg_gain / avg_loss\n",
    "            sub_df['RSI'] = 100 - (100 / (1 + rs))\n",
    "            \n",
    "            # Calculate Daily Returns (percentage change).\n",
    "            sub_df['Daily_Return'] = sub_df['Close'].pct_change() * 100\n",
    "            \n",
    "            # Calculate Volatility: 21-day rolling standard deviation of daily returns.\n",
    "            sub_df['Volatility'] = sub_df['Daily_Return'].rolling(window=21, min_periods=21).std()\n",
    "            \n",
    "            # Standardize selected exogenous variables for this ticker.\n",
    "            # These are the variables you'll later use as regressors in your ARIMAX model.\n",
    "            exog_standard_cols = ['Open', 'Volume', 'MA20', 'Signal', 'RSI', 'Daily_Return', 'Volatility']\n",
    "            scaler = StandardScaler()\n",
    "            # Fit and transform only if there are enough non-NA values.\n",
    "            sub_df[exog_standard_cols] = scaler.fit_transform(sub_df[exog_standard_cols])\n",
    "            \n",
    "            return sub_df\n",
    "        \n",
    "        # Group the data by 'Ticker' and apply the technical indicator calculations and standardization.\n",
    "        # Using include_groups=False to avoid including the grouping column in the transformation.\n",
    "        #df = df.groupby('Ticker').apply(compute_indicators, include_groups=False)\n",
    "        df = df.groupby('Ticker', group_keys=False).apply(compute_indicators)\n",
    "        \n",
    "        # Drop rows with NaN values that result from the rolling calculations.\n",
    "        df_clean = df.dropna().copy()\n",
    "        \n",
    "        logging.info(f\"Preprocessing complete. {len(df_clean)} valid data points after calculating indicators.\")\n",
    "        return df_clean\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error during preprocessing: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fab2dee8-06ad-47a1-bbca-21cd719ff3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_arimax_model(df, forecast_days=7, exog_cols=None):\n",
    "    \"\"\"\n",
    "    Build an ARIMAX model using specified exogenous variables (technical indicators)\n",
    "    to forecast the 'Close' price for a given stock. The DataFrame should have Date as index.\n",
    "\n",
    "    Parameters:\n",
    "    - df: Preprocessed DataFrame, with Date as the index.\n",
    "          It should contain the target variable 'Close' and technical indicators.\n",
    "    - forecast_days: Number of days to forecast (default is 7).\n",
    "    - exog_cols: List of column names to be used as exogenous regressors.\n",
    "                 If None, defaults to ['RSI', 'MACD', 'Volatility'].\n",
    "\n",
    "    Returns:\n",
    "    - A dictionary containing:\n",
    "      - 'forecast': The point forecasts as a NumPy array.\n",
    "      - 'forecast_dates': A list of forecast dates (as strings).\n",
    "      - 'confidence_intervals': A dict with 'lower' and 'upper' bounds arrays.\n",
    "      - 'trend': A simple label (\"UPWARD\", \"DOWNWARD\", or \"NEUTRAL\") based on the forecast.\n",
    "      - 'expected_return': The percentage change from current price to the forecasted price.\n",
    "      - 'current_price': The last observed closing price.\n",
    "      - 'model_info': A dictionary with details (order and AIC) of the fitted ARIMAX model.\n",
    "    \"\"\"\n",
    "\n",
    "    logging.info(\"Building ARIMAX model and generating forecasts...\")\n",
    "\n",
    "    try:\n",
    "        # Define default exogenous regressors if not provided.\n",
    "        if exog_cols is None:\n",
    "            exog_cols = ['Open', 'Volume', 'MA20', 'Signal', 'RSI', 'Daily_Return', 'Volatility']\n",
    "        \n",
    "        # Extract the target series (closing prices) and exogenous variables.\n",
    "        y = df['Close'].values\n",
    "        X = df[exog_cols].values\n",
    "        \n",
    "        # Use auto_arima to select the best ARIMAX model order using the exogenous regressors.\n",
    "        model = auto_arima(\n",
    "            y,\n",
    "            exogenous=X,\n",
    "            start_p=1, start_q=1,\n",
    "            max_p=3, max_q=3,\n",
    "            d=1,\n",
    "            seasonal=False,\n",
    "            trace=True,\n",
    "            error_action='ignore',\n",
    "            suppress_warnings=True,\n",
    "            stepwise=True,\n",
    "            maxiter=100,  # Increase max iterations\n",
    "            method='nm'  # Try Nelder-Mead optimizer\n",
    "        )\n",
    "        order = model.order\n",
    "        logging.info(f\"Best ARIMAX model order: {order}\")\n",
    "        \n",
    "        # Fit the ARIMAX model using the selected order.\n",
    "        arimax_model = ARIMA(y, order=order, exog=X)\n",
    "        arimax_result = arimax_model.fit()\n",
    "        \n",
    "        # For forecasting, we need exogenous values for the forecast period.\n",
    "        # We assume that the exogenous variables remain constant at their last observed values.\n",
    "        last_exog = X[-1, :].reshape(1, -1)  # shape (1, number_of_exog)\n",
    "        forecast_exog = np.repeat(last_exog, forecast_days, axis=0)\n",
    "        \n",
    "        # Generate forecasts using the fitted ARIMAX model.\n",
    "        forecast_results = arimax_result.get_forecast(steps=forecast_days, exog=forecast_exog)\n",
    "        forecast = forecast_results.predicted_mean\n",
    "        conf_int = forecast_results.conf_int(alpha=0.05)\n",
    "        \n",
    "        # Extract confidence intervals whether conf_int is a DataFrame or a NumPy array.\n",
    "        if isinstance(conf_int, pd.DataFrame):\n",
    "            lower_bounds = conf_int.iloc[:, 0].values\n",
    "            upper_bounds = conf_int.iloc[:, 1].values\n",
    "        else:\n",
    "            lower_bounds = conf_int[:, 0]\n",
    "            upper_bounds = conf_int[:, 1]\n",
    "        \n",
    "        # Generate forecast dates based on the last date in the DataFrame's index.\n",
    "        last_date = pd.to_datetime(df.index[-1])\n",
    "        forecast_dates = [(last_date + timedelta(days=i+1)).strftime('%Y-%m-%d') for i in range(forecast_days)]\n",
    "        \n",
    "        # Calculate the expected return and trend based on the last observed price.\n",
    "        current_price = y[-1]\n",
    "        expected_return = ((forecast[-1] - current_price) / current_price) * 100\n",
    "        trend = \"UPWARD\" if forecast[-1] > current_price else \"DOWNWARD\" if forecast[-1] < current_price else \"NEUTRAL\"\n",
    "        \n",
    "        prediction_results = {\n",
    "            'forecast': forecast,\n",
    "            'forecast_dates': forecast_dates,\n",
    "            'confidence_intervals': {\n",
    "                'lower': lower_bounds,\n",
    "                'upper': upper_bounds\n",
    "            },\n",
    "            'trend': trend,\n",
    "            'expected_return': expected_return,\n",
    "            'current_price': current_price,\n",
    "            'model_info': {\n",
    "                'arimax_order': order,\n",
    "                'aic': arimax_result.aic\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        logging.info(f\"Forecast complete. Trend: {trend}, Expected return: {expected_return:.2f}%\")\n",
    "        return prediction_results\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error during ARIMAX model building: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "381a911a-94f3-47c7-a7ba-6f1c8ad66bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Pipeline to Process and Forecast for Each Stock\n",
    "# ----------------------------\n",
    "def run_pipeline(ticker_list, time_period, forecast_days=7, exog_cols=None):\n",
    "    \"\"\"\n",
    "    Complete pipeline: Fetch data, preprocess it, and build ARIMAX forecasts for each ticker.\n",
    "    \n",
    "    Parameters:\n",
    "    - preprocessed_df: DataFrame with Date as index and columns including 'Ticker' and 'Close'.\n",
    "    - forecast_days: Number of days to forecast (default is 7).\n",
    "    \n",
    "    Returns:\n",
    "    - A dictionary where keys are ticker symbols and values are the forecast results dictionary.\n",
    "    \"\"\"\n",
    "    # Fetch raw data\n",
    "    raw_data = fetch_stocks_data(ticker_list, time_period)\n",
    "    if raw_data is None:\n",
    "        logging.error(\"No raw data fetched. Pipeline aborted.\")\n",
    "        return None\n",
    "    \n",
    "    # Preprocess data (compute indicators and standardize exogenous variables)\n",
    "    preprocessed_data = preprocess_data(raw_data)\n",
    "    if preprocessed_data is None:\n",
    "        logging.error(\"Preprocessing failed. Pipeline aborted.\")\n",
    "        return None\n",
    "        \n",
    "    predictions = {}\n",
    "    \n",
    "    # Get the unique tickers present in the DataFrame.\n",
    "    tickers = preprocessed_data['Ticker'].unique()\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        logging.info(f\"Building prediction for {ticker}...\")\n",
    "        # Select data for the ticker.\n",
    "        df_ticker = preprocessed_data[preprocessed_data['Ticker'] == ticker].copy()\n",
    "        \n",
    "        # Ensure the DataFrame is sorted by date.\n",
    "        df_ticker = df_ticker.sort_index()\n",
    "        \n",
    "        # Call the prediction model function for this ticker.\n",
    "        pred = build_arimax_model(df_ticker, forecast_days=forecast_days, exog_cols=exog_cols)\n",
    "        predictions[ticker] = pred\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb9a884d-ea90-4403-8d70-54a71d914860",
   "metadata": {},
   "outputs": [],
   "source": [
    "TICKERS = [\"AAPL\", \"GOOG\", \"MSFT\", \"TSLA\"]\n",
    "TIME_PERIOD = '13y'  # Options: '1m', '3m', '6m', '1y'\n",
    "FORECAST_DAYS = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4604786-878a-4959-ad2b-0a9e79523200",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['Open', 'Volume', 'MA20', 'Signal', 'RSI', 'Daily_Return', 'Volatility']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1a97a7c-c2fe-4d93-9cc6-e7783474ba1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 18:33:24,505 - INFO - Fetching data for multiple tickers...\n",
      "2025-03-26 18:33:24,690 - INFO - Successfully fetched and transformed data for multiple tickers.\n",
      "2025-03-26 18:33:24,691 - INFO - Preprocessing data and calculating technical indicators...\n",
      "C:\\Users\\solom\\AppData\\Local\\Temp\\ipykernel_38936\\3583358415.py:70: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby('Ticker', group_keys=False).apply(compute_indicators)\n",
      "2025-03-26 18:33:24,736 - INFO - Preprocessing complete. 12992 valid data points after calculating indicators.\n",
      "2025-03-26 18:33:24,739 - INFO - Building prediction for AAPL...\n",
      "2025-03-26 18:33:24,742 - INFO - Building ARIMAX model and generating forecasts...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing stepwise search to minimize aic\n",
      " ARIMA(1,1,1)(0,0,0)[0] intercept   : AIC=13003.269, Time=0.49 sec\n",
      " ARIMA(0,1,0)(0,0,0)[0] intercept   : AIC=12999.293, Time=0.27 sec\n",
      " ARIMA(1,1,0)(0,0,0)[0] intercept   : AIC=13001.269, Time=0.32 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 18:33:26,356 - INFO - Best ARIMAX model order: (0, 1, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(0,1,1)(0,0,0)[0] intercept   : AIC=13001.269, Time=0.42 sec\n",
      " ARIMA(0,1,0)(0,0,0)[0]             : AIC=13001.346, Time=0.10 sec\n",
      "\n",
      "Best model:  ARIMA(0,1,0)(0,0,0)[0] intercept\n",
      "Total fit time: 1.609 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 18:33:27,598 - INFO - Forecast complete. Trend: NEUTRAL, Expected return: 0.00%\n",
      "2025-03-26 18:33:27,599 - INFO - Building prediction for GOOG...\n",
      "2025-03-26 18:33:27,602 - INFO - Building ARIMAX model and generating forecasts...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing stepwise search to minimize aic\n",
      " ARIMA(1,1,1)(0,0,0)[0] intercept   : AIC=12225.413, Time=1.10 sec\n",
      " ARIMA(0,1,0)(0,0,0)[0] intercept   : AIC=12231.625, Time=0.24 sec\n",
      " ARIMA(1,1,0)(0,0,0)[0] intercept   : AIC=12230.435, Time=0.30 sec\n",
      " ARIMA(0,1,1)(0,0,0)[0] intercept   : AIC=12230.367, Time=0.41 sec\n",
      " ARIMA(0,1,0)(0,0,0)[0]             : AIC=12232.651, Time=0.11 sec\n",
      " ARIMA(2,1,1)(0,0,0)[0] intercept   : AIC=12234.092, Time=1.07 sec\n",
      " ARIMA(1,1,2)(0,0,0)[0] intercept   : AIC=12227.530, Time=1.02 sec\n",
      " ARIMA(0,1,2)(0,0,0)[0] intercept   : AIC=12231.903, Time=0.54 sec\n",
      " ARIMA(2,1,0)(0,0,0)[0] intercept   : AIC=12232.149, Time=0.39 sec\n",
      " ARIMA(2,1,2)(0,0,0)[0] intercept   : AIC=12236.059, Time=0.98 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 18:33:34,254 - INFO - Best ARIMAX model order: (1, 1, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(1,1,1)(0,0,0)[0]             : AIC=12227.523, Time=0.47 sec\n",
      "\n",
      "Best model:  ARIMA(1,1,1)(0,0,0)[0] intercept\n",
      "Total fit time: 6.642 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 18:33:40,467 - INFO - Forecast complete. Trend: DOWNWARD, Expected return: -2.24%\n",
      "2025-03-26 18:33:40,469 - INFO - Building prediction for MSFT...\n",
      "2025-03-26 18:33:40,473 - INFO - Building ARIMAX model and generating forecasts...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing stepwise search to minimize aic\n",
      " ARIMA(1,1,1)(0,0,0)[0] intercept   : AIC=16778.441, Time=1.45 sec\n",
      " ARIMA(0,1,0)(0,0,0)[0] intercept   : AIC=16803.062, Time=0.35 sec\n",
      " ARIMA(1,1,0)(0,0,0)[0] intercept   : AIC=16782.771, Time=0.52 sec\n",
      " ARIMA(0,1,1)(0,0,0)[0] intercept   : AIC=16780.629, Time=0.59 sec\n",
      " ARIMA(0,1,0)(0,0,0)[0]             : AIC=16805.130, Time=0.15 sec\n",
      " ARIMA(2,1,1)(0,0,0)[0] intercept   : AIC=16779.393, Time=1.20 sec\n",
      " ARIMA(1,1,2)(0,0,0)[0] intercept   : AIC=16779.542, Time=1.26 sec\n",
      " ARIMA(0,1,2)(0,0,0)[0] intercept   : AIC=16777.496, Time=0.77 sec\n",
      " ARIMA(0,1,3)(0,0,0)[0] intercept   : AIC=16779.480, Time=1.47 sec\n",
      " ARIMA(1,1,3)(0,0,0)[0] intercept   : AIC=16774.712, Time=1.66 sec\n",
      " ARIMA(2,1,3)(0,0,0)[0] intercept   : AIC=16775.780, Time=1.49 sec\n",
      " ARIMA(2,1,2)(0,0,0)[0] intercept   : AIC=16791.144, Time=1.35 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 18:33:53,514 - INFO - Best ARIMAX model order: (1, 1, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(1,1,3)(0,0,0)[0]             : AIC=16777.250, Time=0.77 sec\n",
      "\n",
      "Best model:  ARIMA(1,1,3)(0,0,0)[0] intercept\n",
      "Total fit time: 13.022 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 18:34:00,878 - INFO - Forecast complete. Trend: DOWNWARD, Expected return: -1.29%\n",
      "2025-03-26 18:34:00,882 - INFO - Building prediction for TSLA...\n",
      "2025-03-26 18:34:00,886 - INFO - Building ARIMAX model and generating forecasts...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing stepwise search to minimize aic\n",
      " ARIMA(1,1,1)(0,0,0)[0] intercept   : AIC=20666.119, Time=1.67 sec\n",
      " ARIMA(0,1,0)(0,0,0)[0] intercept   : AIC=20663.248, Time=0.42 sec\n",
      " ARIMA(1,1,0)(0,0,0)[0] intercept   : AIC=20664.898, Time=0.48 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 18:34:04,349 - INFO - Best ARIMAX model order: (0, 1, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ARIMA(0,1,1)(0,0,0)[0] intercept   : AIC=20664.910, Time=0.66 sec\n",
      " ARIMA(0,1,0)(0,0,0)[0]             : AIC=20661.990, Time=0.21 sec\n",
      "\n",
      "Best model:  ARIMA(0,1,0)(0,0,0)[0]          \n",
      "Total fit time: 3.452 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 18:34:05,978 - INFO - Forecast complete. Trend: NEUTRAL, Expected return: 0.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticker: AAPL\n",
      "{'forecast': array([223.75, 223.75, 223.75, 223.75, 223.75, 223.75, 223.75]), 'forecast_dates': ['2025-03-26', '2025-03-27', '2025-03-28', '2025-03-29', '2025-03-30', '2025-03-31', '2025-04-01'], 'confidence_intervals': {'lower': array([221.43562071, 220.47697341, 219.74137747, 219.12124141,\n",
      "       218.57489057, 218.08095166, 217.62672795]), 'upper': array([226.06437929, 227.02302659, 227.75862253, 228.37875859,\n",
      "       228.92510943, 229.41904834, 229.87327205])}, 'trend': 'NEUTRAL', 'expected_return': 0.0, 'current_price': 223.75, 'model_info': {'arimax_order': (0, 1, 0), 'aic': 10310.014030955805}}\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "Ticker: GOOG\n",
      "{'forecast': array([171.62662442, 170.77211884, 170.14447631, 169.68346685,\n",
      "       169.34485099, 169.09613439, 168.91344966]), 'forecast_dates': ['2025-03-26', '2025-03-27', '2025-03-28', '2025-03-29', '2025-03-30', '2025-03-31', '2025-04-01'], 'confidence_intervals': {'lower': array([169.8821024 , 168.60236406, 167.77328586, 167.2078974 ,\n",
      "       166.81292901, 166.53297299, 166.33257967]), 'upper': array([173.37114644, 172.94187363, 172.51566676, 172.1590363 ,\n",
      "       171.87677296, 171.65929579, 171.49431966])}, 'trend': 'DOWNWARD', 'expected_return': -2.2435000706291204, 'current_price': 172.7899932861328, 'model_info': {'arimax_order': (1, 1, 1), 'aic': 8480.007165657637}}\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "Ticker: MSFT\n",
      "{'forecast': array([393.25760645, 392.53761708, 391.84568589, 391.2689042 ,\n",
      "       390.78810911, 390.38732677, 390.05324166]), 'forecast_dates': ['2025-03-26', '2025-03-27', '2025-03-28', '2025-03-29', '2025-03-30', '2025-03-31', '2025-04-01'], 'confidence_intervals': {'lower': array([389.42508026, 388.0186662 , 386.86366371, 385.987886  ,\n",
      "       385.30805456, 384.77240955, 384.34590307]), 'upper': array([397.09013264, 397.05656796, 396.82770807, 396.5499224 ,\n",
      "       396.26816367, 396.00224399, 395.76058024])}, 'trend': 'DOWNWARD', 'expected_return': -1.2923276545388866, 'current_price': 395.1600036621094, 'model_info': {'arimax_order': (1, 1, 3), 'aic': 13618.942009029332}}\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "Ticker: TSLA\n",
      "{'forecast': array([288.14001465, 288.14001465, 288.14001465, 288.14001465,\n",
      "       288.14001465, 288.14001465, 288.14001465]), 'forecast_dates': ['2025-03-26', '2025-03-27', '2025-03-28', '2025-03-29', '2025-03-30', '2025-03-31', '2025-04-01'], 'confidence_intervals': {'lower': array([279.62006605, 276.09098778, 273.38303079, 271.10011744,\n",
      "       269.08883041, 267.27048794, 265.59834946]), 'upper': array([296.65996325, 300.18904151, 302.8969985 , 305.17991185,\n",
      "       307.19119889, 309.00954136, 310.68167983])}, 'trend': 'NEUTRAL', 'expected_return': 0.0, 'current_price': 288.1400146484375, 'model_info': {'arimax_order': (0, 1, 0), 'aic': 18773.410606413658}}\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "# Assume `preprocessed_data` is your DataFrame after calling preprocess_data()\n",
    "all_predictions = run_pipeline(ticker_list = TICKERS, time_period = TIME_PERIOD, exog_cols=col)\n",
    "\n",
    "# To print the prediction for each ticker:\n",
    "for ticker, prediction in all_predictions.items():\n",
    "    print(f\"Ticker: {ticker}\")\n",
    "    print(prediction)\n",
    "    print(\"-----------------------------------------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d8fa2e-f820-49c6-899b-a9ba30c24d37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
